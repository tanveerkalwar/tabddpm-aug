"""
Privacy evaluation via Membership Inference Attack (MIA).
"""
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score


def membership_inference_attack(real_train, synthetic, real_test):
    """
    Perform MIA following Hayes et al. (2019).

    Args:
        real_train: Real training samples used as "members".
        synthetic: Synthetic samples generated by the model under evaluation.
        real_test: Real test samples (currently unused).

    Returns:
        float: MIA AUC (0.5 = perfect privacy, 1.0 = total memorization).
    """
    n_samples = min(len(real_train), len(synthetic))
    if n_samples < 20: return 0.5 # Not enough data for a reliable attack
    X_member = np.vstack([real_train[:n_samples], synthetic[:n_samples]])
    y_member = np.hstack([np.ones(n_samples), np.zeros(n_samples)])
    clf = RandomForestClassifier(n_estimators=50, max_depth=10, random_state=42)
    X_tr, X_te, y_tr, y_te = train_test_split(X_member, y_member, test_size=0.3, random_state=42, stratify=y_member)
    clf.fit(X_tr, y_tr)
    y_pred_proba = clf.predict_proba(X_te)[:, 1]
    return float(roc_auc_score(y_te, y_pred_proba))
